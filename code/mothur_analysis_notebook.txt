# how we analyzed the entire GF mouse dataset, start to finish
# Kaitlin Flynn, Nick Lesniak
# Updated 12-1-16

# file prep
# download fastqs from NAS onto axiom

# gunzip 
/mnt/EXT/Schloss-data/bin/quicksubmit "gunzip *.gz" --walltime 500:00:00 --cput 500:00:00

# make files file
python
import glob 
with open("gf_new.files", 'w') as outfile:
	for R1 in glob.glob('*R1*.fastq'):
		outfile.write('{0}\t{1}\t{2}\n'.format(R1.split('_')[0],R1,R1.replace('R1','R2')))
		
# set up batch file for first half of mothur analysis pipleline and qsub to axiom

# batch file: gf_new.batch
set.dir(input=/mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw, output=/mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw)
make.contigs(file=gf_new.files, processors=8)
set.dir(input=/mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw, output=/mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw)
summary.seqs(fasta=gf_new.trim.contigs.fasta)
screen.seqs(fasta=gf_new.trim.contigs.fasta, group=gf_new.contigs.groups, summary=gf_new.trim.contigs.summary, maxambig=0, maxlength=275, processors=8)
summary.seqs(fasta=gf_new.trim.contigs.good.fasta)
unique.seqs(fasta=gf_new.trim.contigs.good.fasta)
count.seqs(name=gf_new.trim.contigs.good.names, group=gf_new.contigs.good.groups)
summary.seqs(count=gf_new.trim.contigs.good.count_table)
pcr.seqs(fasta=/mnt/EXT/Schloss-data/kaitlin/silva.bacteria.fasta, start=11894, end=25319, keepdots=F, processors=8)
system(mv /mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw/silva.bacteria.pcr.fasta /mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw/silva.v4.fasta)
align.seqs(fasta=gf_new.trim.contigs.good.unique.fasta, reference=/mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw/silva.v4.fasta, processors=8)
summary.seqs(fasta=gf_new.trim.contigs.good.unique.align, count=gf_new.trim.contigs.good.count_table, processors=8)
screen.seqs(fasta=gf_new.trim.contigs.good.unique.align, count=gf_new.trim.contigs.good.count_table, summary=gf_new.trim.contigs.good.unique.summary, start=1968, end=11550, maxhomop=8)
summary.seqs(fasta=current, count=current)
filter.seqs(fasta=gf_new.trim.contigs.good.unique.good.align, vertical=T, trump=.)
unique.seqs(fasta=gf_new.trim.contigs.good.unique.good.filter.fasta, count=gf_new.trim.contigs.good.good.count_table)
pre.cluster(fasta=/mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw/gf_new.trim.contigs.good.unique.good.filter.unique.fasta, count=/mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw/gf_new.trim.contigs.good.unique.good.filter.count_table, diffs=2, processors=2)
chimera.uchime(fasta=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.fasta, count=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.count_table, dereplicate=t, processors=2)
remove.seqs(fasta=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.fasta, accnos=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.accnos)
summary.seqs(fasta=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta, count=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.count_table, processors=2)
classify.seqs(fasta=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, count=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.count_table, reference=/mnt/EXT/Schloss-data/kaitlin/trainset14_032015.pds.fasta, taxonomy=/mnt/EXT/Schloss-data/kaitlin/trainset14_032015.pds.tax, cutoff=80, processors=2)
remove.lineage(fasta=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta, count=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.count_table, taxonomy=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.taxonomy, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)
remove.groups(count=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.count_table, fasta=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta, taxonomy=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.taxonomy, groups=mock1-Mock1-mock2-mock-Mock)

# Run separate commands or batch file for cluster.split step- needs more memory 
# first step: this will spit out a bunch of .dist files and .temp files
# it will also make ".file" file that gets used in the next cluster.split step
# ran with ppn = 2 and mem = 47gb settings in PBS script
cluster.split(fasta=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.fasta, count=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table, taxonomy=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.pick.taxonomy, splitmethod=classify, taxlevel=4, cutoff=0.15, processors=2, cluster=F)

# step 2
# ran with ppn = 1 and mem = 100gb in PBS script
cluster.split(file=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.file, processors=1)

# remove cdiff sequences and make shared file
set.dir(input=/mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw, output=/mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw)
remove.seqs(accnos=new_cdiff.seq.accnos, list=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.list)
remove.seqs(accnos=new_cdiff.seq.accnos, count=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.count_table)
make.shared(list=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.0.03.pick.list, count=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.pick.count_table)
classify.otu(list=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.0.03.pick.list, count=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.denovo.uchime.pick.pick.pick.pick.count_table, taxonomy=gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.pick.taxonomy)
system(mv gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.an.unique_list.0.03.pick.shared gf_new.an.shared)
system(mv /mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw/gf_new.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.an.unique_list.0.03.cons.taxonomy /mnt/EXT/Schloss-data/kaitlin/Schubert_humanCdGF_XXXX_2016/data/raw/gf_new.an.cons.taxonomy)
sub.sample(shared=gf_new.an.shared, size=2000)


# Mothur commands for analysis 

# NMDS
# first need to subset your shared file to only get the samples you want to compare in R. write out to new file and put on axiom
# in mothur

dist.shared(shared=inocula.shared, iters=2000, subsample=2000, calc=thetayc)
nmds(phylip=inocula.thetayc.0.03.lt.ave.dist)
